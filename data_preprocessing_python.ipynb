{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing steps\n",
    "\n",
    "This notebook will read the svs files in the data file using openslide python and apply the following pre-processing steps:\n",
    "\n",
    "-Crop the images in small batches of size 896*896\n",
    "\n",
    "-Filter out the tiles that contain less than 90% of brain (Tumor??) tissue: Hysteresis thresholding on the grayscale and 8-bit depth complemented image (http://ac.els-cdn.com/S1361841515001838/1-s2.0-S1361841515001838-main.pdf?_tid=f96cb1fa-35ba-11e7-b61d-00000aab0f6b&acdnat=1494446462_d2ee895640e38bd660bc559fc6233d34)\n",
    "\n",
    "-Optional: Nuclei segmentation using morphometric top-hat filtering and hysteresis thresholding (http://ac.els-cdn.com/S1361841515001838/1-s2.0-S1361841515001838-main.pdf?_tid=f96cb1fa-35ba-11e7-b61d-00000aab0f6b&acdnat=1494446462_d2ee895640e38bd660bc559fc6233d34)\n",
    "\n",
    "-Further tile to 224*224 (input size of a ResNet or Inception CNN)\n",
    "\n",
    "input_size $= N*224*224*(1 \\ or \\ 3)$\n",
    "\n",
    "label_size $= N$\n",
    "\n",
    "N = Number_of_images * Number_of_patches\n",
    "\n",
    "For now, the notebook only treats one svs file : \"test.svs\". The pre-processing steps are very computationnally expensive so we need to parallelize the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openslide import *\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import feature\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.ndimage import (gaussian_filter,\n",
    "                           generate_binary_structure, binary_erosion, label)\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# modified from Canny edge detection algo\n",
    "# https://github.com/scikit-image/scikit-image/blob/master/skimage/feature/_canny.py#L53\n",
    "def canny_hyst(image, low_threshold, high_threshold):\n",
    "    #\n",
    "    # The steps involved:\n",
    "    #\n",
    "    # * Label all points above the high threshold as edges.\n",
    "    # * Recursively label any point above the low threshold that is 8-connected\n",
    "    #   to a labeled point as an edge.\n",
    "    #\n",
    "    # Regarding masks, any point touching a masked point will have a gradient\n",
    "    # that is \"infected\" by the masked point, so it's enough to erode the\n",
    "    # mask by one and then mask the output. We also mask out the border points\n",
    "    # because who knows what lies beyond the edge of the image?\n",
    "    #\n",
    "\n",
    "    #\n",
    "    #---- Create two masks at the two thresholds.\n",
    "    #\n",
    "    high_mask = (image >= high_threshold)\n",
    "    low_mask = (image >= low_threshold)\n",
    "    #\n",
    "    # Segment the low-mask, then only keep low-segments that have\n",
    "    # some high_mask component in them\n",
    "    #\n",
    "    strel = np.ones((3, 3), bool)\n",
    "    labels, count = label(low_mask, strel)\n",
    "    if count == 0:\n",
    "        return low_mask\n",
    "\n",
    "    sums = (np.array(ndi.sum(high_mask, labels,\n",
    "                             np.arange(count, dtype=np.int32) + 1),\n",
    "                     copy=False, ndmin=1))\n",
    "    good_label = np.zeros((count + 1,), bool)\n",
    "    good_label[1:] = sums > 0\n",
    "    output_mask = good_label[labels]\n",
    "    return output_mask\n",
    "\n",
    "def greyscale(img):\n",
    "    # http://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
    "    # Method #1: PIL conversion\n",
    "    #pil_greyscale = Image.fromarray(img, 'RGB').convert(mode = 'L')\n",
    "    #pil_greyscale = np.array(pil_greyscale.getdata()).reshape((H, W,))\n",
    "    #print (\"PIL conversion\")\n",
    "    #plt.imshow(pil_greyscale.astype('uint8'), cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "    # Method #2: LUMA coding\n",
    "    luma_greyscale = np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "    return luma_greyscale\n",
    "\n",
    "def autocontrast(grey_img):\n",
    "    H, W = grey_img.shape\n",
    "    # Translated Divakar's Matlab code\n",
    "    # https://www.mathworks.com/matlabcentral/fileexchange/10566-auto-contrast\n",
    "    low_limit=0.008\n",
    "    up_limit=0.992\n",
    "    grey_img_flat = np.sort(grey_img.reshape(H * W))\n",
    "    #print (grey_img_flat[int(np.ceil(low_limit*H*W))], grey_img_flat[int(np.ceil(up_limit*H*W))])\n",
    "    v_min = grey_img_flat[int(np.ceil(low_limit*H*W))]\n",
    "    v_max = grey_img_flat[int(np.ceil(up_limit*H*W))]\n",
    "    grey_img = (grey_img-v_min)/(v_max-v_min)\n",
    "    grey_img *= 255\n",
    "    #Do we need a reshape here?\n",
    "    return grey_img\n",
    "\n",
    "def complement(grey_img):\n",
    "    # Performing 8-bit complement\n",
    "    # http://micro.magnet.fsu.edu/primer/java/digitalimaging/processing/complementimage/\n",
    "    return 255 - grey_img\n",
    "    \n",
    "def filtering (img, debug = False):\n",
    "    if debug:\n",
    "        print (\"Original Image\")\n",
    "        plt.imshow(img.astype('uint8'))\n",
    "        plt.show()\n",
    "    \n",
    "    H, W, C = img.shape\n",
    "\n",
    "    # Grayscale\n",
    "    img = greyscale(img)\n",
    "    if debug:\n",
    "        print (\"LUMA coding\")\n",
    "        plt.imshow(img.astype('uint8'), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # TODO: This doesnt give us the results we are looking for\n",
    "    # Autocontrast\n",
    "    #img = autocontrast(img)\n",
    "    #if debug:\n",
    "    #    print (\"Auto Contrast\")\n",
    "    #    plt.imshow(img.astype('uint8'), cmap='gray')\n",
    "    #    plt.show()\n",
    "\n",
    "    # Performing 8-bit complement\n",
    "    # http://micro.magnet.fsu.edu/primer/java/digitalimaging/processing/complementimage/\n",
    "    img = complement(img)\n",
    "    if debug:\n",
    "        print (\"8-bit Complement\")\n",
    "        plt.imshow(img.astype('uint8'), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # Hysteresis Thresholding\n",
    "    img = canny_hyst(img, 50, 100)\n",
    "    if debug:\n",
    "        print (\"Hysteresis 2\")\n",
    "        plt.imshow(img.astype('uint8'), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    if debug:\n",
    "        print (float(np.sum(img)))\n",
    "        print (float(np.sum(img)) / (H*W))\n",
    "    return float(np.sum(img)) / (H*W)\n",
    "\n",
    "\n",
    "def generate_valid_patches(filename, patch_size=224):\n",
    "    img = OpenSlide(\"/home/cedoz/radiogenomics/data/%s\"%filename)\n",
    "    width, height = img.dimensions\n",
    "    \n",
    "    print(\"building and filtering patches...\")\n",
    "    X_train = np.zeros((1, patch_size, patch_size, 3))\n",
    "    for i in range(int(height/patch_size)):\n",
    "        print (\"iteration %d out of %d\"%(i,int(height/patch_size)))\n",
    "        for j in range(int(width/patch_size)):\n",
    "            idx = i*int(width/patch_size) + j\n",
    "            patch = img.read_region(location = (j*patch_size,i*patch_size), level = 0, size = (patch_size,patch_size))\n",
    "            patch = np.array(patch.getdata())[:,0:-1].reshape((patch_size, patch_size, 3))\n",
    "            if filtering(patch) >= 0.5:\n",
    "                patch = np.expand_dims(patch, axis = 0)\n",
    "                X_train = np.append(X_train, patch, axis = 0)\n",
    "    X_train = X_train[1:]\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook data_preprocessing_python.ipynb to script\n",
      "[NbConvertApp] Writing 6686 bytes to data_preprocessing_python.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script data_preprocessing_python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
